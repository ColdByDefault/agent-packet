#!/usr/bin/env python3
"""
Debug version of example.py with more detailed error output.
"""

import asyncio
import os
import sys
import traceback
from pathlib import Path

# Add src to path to import the agent
sys.path.insert(0, str(Path(__file__).parent / "src"))

from llm_agent import LocalLLMAgent, AgentConfig
from llm_agent.core.config import OllamaConfig, RAGConfig, MCPConfig

async def main():
    """Main example function with detailed error handling."""
    print("üöÄ Local LLM Agent Example (Debug Mode)")
    print("=" * 50)
    
    try:
        # Create configuration
        config = AgentConfig(
            agent_name="MyLocalAgent",
            system_prompt="""You are a helpful AI assistant running locally. You have access to:
            - Your local knowledge base for retrieving relevant information
            - Various tools for calculations, text search, and system information
            - The ability to remember our conversation
            
            Always be helpful, accurate, and mention when you're using your knowledge base or tools.""",
            
            # Configure for your local setup
            ollama=OllamaConfig(
                base_url="http://localhost:11434",
                model="llama3.1:8b",  # Using your installed model
                temperature=0.7
            ),
            
            rag=RAGConfig(
                vector_db_path="./data/vectordb",
                embedding_model="nomic-embed-text:latest",  # Using your embedding model
                chunk_size=800,
                max_results=5
            ),
            
            mcp=MCPConfig(
                enabled=True,
                server_port=8001
            )
        )
        
        print("‚úÖ Configuration created successfully")
        print(f"   ‚Ä¢ Ollama URL: {config.ollama.base_url}")
        print(f"   ‚Ä¢ Model: {config.ollama.model}")
        print(f"   ‚Ä¢ Embedding: {config.rag.embedding_model}")
        
        # Initialize the agent
        print("\nüîß Initializing agent components...")
        async with LocalLLMAgent(config) as agent:
            print("‚úÖ Agent initialized successfully!")
            
    except Exception as e:
        print(f"\n‚ùå Detailed Error Information:")
        print(f"   Error Type: {type(e).__name__}")
        print(f"   Error Message: {str(e)}")
        print(f"\nüìã Full Traceback:")
        traceback.print_exc()
        
        print(f"\nüîç Debugging Information:")
        print(f"   ‚Ä¢ Python Path: {sys.path[:3]}...")
        print(f"   ‚Ä¢ Working Directory: {os.getcwd()}")
        print(f"   ‚Ä¢ Python Version: {sys.version}")

if __name__ == "__main__":
    # Setup logging
    import logging
    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Example interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Outer Error: {e}")
        traceback.print_exc()