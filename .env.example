# Local LLM Agent Configuration
# Copy this file to .env and customize as needed

# Environment
ENVIRONMENT=development
DEBUG=true

# Agent Configuration
AGENT_NAME=LocalLLMAgent
MAX_CONVERSATION_LENGTH=20
SYSTEM_PROMPT="You are a helpful AI assistant with access to local knowledge and tools."

# Ollama Configuration
OLLAMA__BASE_URL=http://localhost:11434
OLLAMA__MODEL=llama3.1:8b
OLLAMA__TEMPERATURE=0.7
OLLAMA__TOP_P=0.9
OLLAMA__MAX_TOKENS=2048
OLLAMA__TIMEOUT=120

# RAG Configuration
RAG__VECTOR_DB_PATH=./data/vectordb
RAG__EMBEDDING_MODEL=nomic-embed-text:latest
RAG__CHUNK_SIZE=1000
RAG__CHUNK_OVERLAP=200
RAG__MAX_RESULTS=5
RAG__SIMILARITY_THRESHOLD=0.7

# MCP Configuration
MCP__ENABLED=true
MCP__SERVER_PORT=8001
MCP__MAX_CONNECTIONS=10

# Logging Configuration
LOGGING__LEVEL=INFO
LOGGING__FILE_PATH=./logs/agent.log
LOGGING__ROTATION=10 MB